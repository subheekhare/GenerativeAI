{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dCmqvqboGFRI"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-huggingface\n",
        "!pip install huggingface-hub\n",
        "!pip install langchain-community\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsLRtz-yHX-Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "hf_token_id=userdata.get('HF_TOKEN')\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = hf_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "T4Rp4ztiGPV9"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMR0__xR7NGY"
      },
      "outputs": [],
      "source": [
        "#loading the model in memory\n",
        "model_id=\"meta-llama/Llama-2-7b-chat-hf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcdRffdzFbpw"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7IXchgJ4OO0"
      },
      "outputs": [],
      "source": [
        "quantization_config=BitsAndBytesConfig(\n",
        "    load_in_4bit=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUoNsDLM50M-"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quantization_config, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnMdPaa9daRq"
      },
      "outputs": [],
      "source": [
        "pipe= pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "hf = HuggingFacePipeline(pipeline=pipe,pipeline_kwargs={\"temperature\": 0.1, \"new_max_tokens\": 100})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI0ewoDAeY2n"
      },
      "outputs": [],
      "source": [
        "hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SImfQ14afhVp"
      },
      "outputs": [],
      "source": [
        "hf.invoke(\"Hi there. how are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7kaCZ0XLd5-"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate, LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEgQ5Uc6b8CK"
      },
      "outputs": [],
      "source": [
        "question=\"how to perform EDA on IMDB moview reviews?\"\n",
        "# \"who is a first president of INDIA?\"\n",
        "template=\"\"\"Question: {queston}\n",
        "give me a answer in detail manner and in step by step manner\"\"\"\n",
        "\n",
        "prompt=PromptTemplate(template=template,input_variables=[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVqE08_Gb8Zn"
      },
      "outputs": [],
      "source": [
        "llm_chain=LLMChain(llm=hf,prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqC9rVIziHhd"
      },
      "outputs": [],
      "source": [
        "llm_chain.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQj6wbK7irDn"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.runnable import RunnableSequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_chain = RunnableSequence(prompt,hf )"
      ],
      "metadata": {
        "id": "E1XLAAxjUlqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_chain.invoke(question)"
      ],
      "metadata": {
        "id": "L_-b--69Upg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EVyh_Q2rVHhA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}